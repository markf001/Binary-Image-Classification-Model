# -*- coding: utf-8 -*-
"""Machine Learning Assignment 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1e3hdA06z4G8Af_iTSout-Gb1BjYwWUn3
"""

import os
import shutil
import math
import numpy as np
import tensorflow as tf
import pandas as pd
import matplotlib.pyplot as plt

from tensorflow import keras
from keras._tf_keras.keras.preprocessing.image import ImageDataGenerator
from keras._tf_keras.keras.models import Sequential
from keras._tf_keras.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from keras._tf_keras.keras.optimizers import Adam

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle

!kaggle datasets download -d rm1000/brain-tumor-mri-scans

!unzip brain-tumor-mri-scans.zip

!rm -r sample_data

healthy_dir = '/content/healthy'
meningioma_dir = '/content/meningioma'
pituitary_dir = '/content/pituitary'
glioma_dir = '/content/glioma'

train_dir = '/content/train'
validate_dir = '/content/validate'
test_dir = '/content/test'

os.makedirs(os.path.join(train_dir, 'healthy'), exist_ok=True)
os.makedirs(os.path.join(train_dir, 'meningioma'), exist_ok=True)
os.makedirs(os.path.join(train_dir, 'pituitary'), exist_ok=True)
os.makedirs(os.path.join(train_dir, 'glioma'), exist_ok=True)

os.makedirs(os.path.join(validate_dir, 'healthy'), exist_ok=True)
os.makedirs(os.path.join(validate_dir, 'meningioma'), exist_ok=True)
os.makedirs(os.path.join(validate_dir, 'pituitary'), exist_ok=True)
os.makedirs(os.path.join(validate_dir, 'glioma'), exist_ok=True)

os.makedirs(os.path.join(test_dir, 'healthy'), exist_ok=True)
os.makedirs(os.path.join(test_dir, 'meningioma'), exist_ok=True)
os.makedirs(os.path.join(test_dir, 'pituitary'), exist_ok=True)
os.makedirs(os.path.join(test_dir, 'glioma'), exist_ok=True)

def split_data(source_dir, train_dir, validate_dir, test_dir, train_split=0.70, validate_split=0.15):
    files = os.listdir(source_dir)
    np.random.shuffle(files)

    train_size = int(len(files) * train_split)
    validate_size = int(len(files)* validate_split)

    train_files = files[:train_size]
    validate_files = files[train_size:train_size + validate_size]
    test_files = files[train_size + validate_size:]

    for file in train_files:
        shutil.copy(os.path.join(source_dir, file), os.path.join(train_dir, file))

    for file in validate_files:
        shutil.copy(os.path.join(source_dir, file), os.path.join(validate_dir, file))

    for file in test_files:
        shutil.copy(os.path.join(source_dir, file), os.path.join(test_dir, file))


split_data(healthy_dir, os.path.join(train_dir, 'healthy'),
           os.path.join(validate_dir, 'healthy'),
           os.path.join(test_dir, 'healthy'))

split_data(meningioma_dir, os.path.join(train_dir, 'meningioma'),
           os.path.join(validate_dir, 'meningioma'),
           os.path.join(test_dir, 'meningioma'))

split_data(pituitary_dir, os.path.join(train_dir, 'pituitary'),
           os.path.join(validate_dir, 'pituitary'),
           os.path.join(test_dir, 'pituitary'))

split_data(glioma_dir, os.path.join(train_dir, 'glioma'),
           os.path.join(validate_dir, 'glioma'),
           os.path.join(test_dir, 'glioma'))

print("Data has been split into training, validation, and testing datasets.")

train_datagen = ImageDataGenerator(rescale=1./255)
validate_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir, target_size=(75, 75), batch_size=32, class_mode='categorical')

validate_generator = validate_datagen.flow_from_directory(
    validate_dir, target_size=(75, 75), batch_size=32, class_mode='categorical')

test_generator = test_datagen.flow_from_directory(
    test_dir, target_size=(75, 75), batch_size=32, class_mode='categorical', shuffle=False)

# Display class labels
print(f"Class labels: {train_generator.class_indices}")

class_indices = train_generator.class_indices
class_labels = list(class_indices.keys())
class_counts = train_generator.classes.sum(axis=0)

print(f"Class distribution:")
for i, label in enumerate(class_labels):
    print(f"{label}: {np.sum(train_generator.classes == i)}")

class_indices = validate_generator.class_indices
class_labels = list(class_indices.keys())
class_counts = validate_generator.classes.sum(axis=0)

print(f"Distribution:")
for i, label in enumerate(class_labels):
    print(f"{label}: {np.sum(validate_generator.classes == i)}")

class_indices = test_generator.class_indices
class_labels = list(class_indices.keys())
class_counts = test_generator.classes.sum(axis=0)

print(f"Distribution:")
for i, label in enumerate(class_labels):
    print(f"{label}: {np.sum(test_generator.classes == i)}")

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(75, 75, 3)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(4, activation='softmax')
])

model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()

# Train model
history = model.fit(
    train_generator,
    steps_per_epoch=len(train_generator),
    epochs=20,
    validation_data=validate_generator,
    validation_steps=len(validate_generator)
)

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

model.save('tumor_classification.keras')